% !TeX root = ../__ylc_main.tex

\chapter{评估分析}

为了衡量本研究提出的解题过程评估系统的有效性，我们在真实教学场景中采集学生的解题数据，并请教师以及人类专家对其进行分析。本章节将介绍我们的实验设计、流程和实验分析。

\section{实验设计与流程}

\subsection{参与者}

我们在西宁二十一中实地考察期间组织了用户实验，实验参与者包括两名高中数学老师以及老师帮助我们选出的20位高二学生。学生的年龄在16-18岁之间，数学水平大致能够反映班级中的分布。

\subsection{实验流程}

我们选用当天数学作业中的一道解答题作为实验题目，要求学生现场作答，不限时。我们要求被试在做题的过程中需要尽可能边思考边说 (也称作 think aloud)，就像平常练习一样自然地解题，但是尽可能把解题过程中的真实想法和思路说出来。测试所用题目如下：

\begin{quote}
    \begin{description}
        \item[实验题目] 已知函数 $f(x) = ax^2 + b \ln x$ 在 $x=1$ 处有极值 $\frac{1}{2}$.

        (1) 求 $a, b$ 的值;

        (2) 求出 $f(x)$ 的单调区间，并求极值.

    \end{description}
\end{quote}

考虑到后期实际落地的成本，不太可能位每一个学生都配备手写板和智能平板，本次实验仅记录音频和图片信息，探究我们的系统基于这些信息进行分析的效果。学生在解答过程中，实验人员使用手机对学生的解题过程进行录音记录，并在解题完成后对答题纸拍照留存。学生完成解答后，我们将数据汇总并逐一进行解题过程的思路建模和错因分析。

在20份学生解答中，我们选取了字迹较为工整、数据质量较高且具有代表性的 8 份解答过程，将解题过程评估系统给出的分析报告进行汇总，交给老师对这些解答过程的分析结果依次进行评分。共有 5 位被试对系统的输出进行了评分，包括两位老师和 3 位 校内被试。此外我们还通过一个简短的访谈请两位老师对系统使用体验进行总体上的评价。

\subsection{评价方式}

对于一份学生解题过程，系统给出的解题分析报告的例子如图\ref{fig:analysis_example}。为了衡量评判的准确程度，老师需要判断系统对于每一步正确性判断是否正确，以及根本错因分析是否有冗余或缺失。

在随后的访谈部分，我们请教师从实际应用角度衡量我们系统能够有多大帮助。具体来讲，我们请老师思考对于“收齐全班的作业，在批改的过程中分析每位学生的错误点，并对全班的知识掌握情况有所了解，从而指导第二天根据作业情况进行针对性教学”这一任务，考虑以下两种方法来实现的情景，并从多个维度进行对比打分：

\begin{enumerate}
    \item 按传统方式手动批改，在答卷上批注，并总结全班掌握情况；
    \item 使用我们的系统，直接浏览每位学生的解题分析报告以及全班的统计数据。如有必要也可以直接查看答卷。
\end{enumerate}

我们使用基于 NASA-TLX \footnote{NASA Task Load Index (NASA-TLX) 是一个客观的、多维度的任务负荷评估方式，在人机交互研究中广泛使用。}的问卷来衡量老师对于两种完成任务方法分别的认知负荷，要求老师对以下命题按照 1 - 7 的分数标准进行评分(1 代表程度最低，7 代表程度最高)：

\begin{itemize}
    \item 脑力需求：任务需要多少心理和知觉活动（如思考、决定、计算、记忆等）
    \item 体力需求：任务需要多少体力活动（实际进行思考之外的活动）
    \item 时间需求：时间的压力有多大（如时间限制、任务速度等）
    \item 自我表现：对自己执行任务的表现是否满意，完成任务的成功程度
    \item 努力程度：为了完成任务需要付出多少努力（工作量）
    \item 挫折感：在完成任务过程中感受到多少压力、沮丧和挫折感
\end{itemize}

随后我们要求老师从以下方面对总体使用体验进行评价，同样按照 1 - 7 的分数标准进行评分(1 代表完全不认同，7 代表非常认同)：

\begin{itemize}
    \item 目前的解题分析报告是否足够清晰简洁、易于理解？
    \item 总体而言，您在多大程度上相信我们系统给出的判断？
    \item 未来如果自动判作业系统开发成熟，您多大程度上愿意使用它来辅助教学？
\end{itemize}

\section{实验结果分析}

\subsection{系统准确性}

经过专家评估，在上述实验中选用的 8 份解答过程中，系统对于每一步骤学生解答的正确性判断准确率平均为 98.25\%；根本错误点分析准确性则稍微弱一点，对于每一份解答过程的分析报告中，根本错因分析平均有 10\% 的概率发生冗余，以及 10\% 的概率发生遗漏。在实际应用中，系统的准确性表现得较为稳定，虽然准确性仍有待提高，对于大部分学生的解答过程都能给出对于老师的教学有参考价值的分析报告。

\subsection{访谈结论}

在访谈部分，我们请老师对于两种完成任务方法的认知负荷进行评分，结果如表\ref{tab:nasa-tlx}所示(多位被试的打分取均值)。从表中可以看出，老师在使用我们的系统进行任务的认知负荷要明显低于传统手动批改的方式，具体体现在对于脑力、体力、时间的需求以及努力程度上，使用我们系统所需要付出的都更低。这是因为老师可以省去逐一批改学生的作业并记忆常见的错误原因与易错点，直接参考系统给出的对于班级整体批改后得到的统计数据。在自我表现和挫折感这两个维度上，老师对于使用我们系统的评价都略优于传统手动批改的方式。这说明我们的系统在实际应用中能够有效地减轻老师的工作负担。

\begin{table}
    \centering
    \caption{认知负荷评分结果}
    \label{tab:nasa-tlx}
    \begin{tabular}{c|cccccc}
        \toprule
        & \textbf{脑力需求} & \textbf{体力需求} & \textbf{时间需求} & \textbf{自我表现} & \textbf{努力程度} & \textbf{挫折感} \\
        \midrule
        \textbf{传统手动批改} & 5.5 & 4.5 & 5.0 & 4.0 & 5.0 & 4.5 \\
        \textbf{使用我们系统} & 3.5 & 3.0 & 3.0 & 5.0 & 3.5 & 4.0 \\
        \bottomrule
    \end{tabular}
\end{table}

总体来讲老师认为我们的系统给出的分析报告比较清晰易懂(6.5 分)，并且在一定程度上相信系统给出的判断(5.5 分)。在未来如果自动判作业系统开发成熟，老师愿意使用它来辅助教学的意愿也较高(6.0 分)。

老师特别表达了希望看到全班的错误点和错因统计结果的意愿，因为对于老师的实际教学来说，全班的知识掌握情况对于通过大班授课来进行针对性指导是更为重要的。基于目前每道题的自动批改结果，我们已经能够一定程度上达到这一目标。对于每一道题，我们可以整理所有答卷中有错误的数量；可以统计每个错误点出现的次数并进行排序，从而了解到全班的易错点有哪些；还可以整理未掌握人数较多的知识点进行针对性讲解。我们访谈的老师认为这一点在实际应用中是非常有意义的。

