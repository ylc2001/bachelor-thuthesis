% !TeX root = ../__ylc_main.tex

\chapter{结论}

\section{研究成果}

本研究成功提出了一种基于大语言模型 (LLM) 的学生思维能力评估方法，通过对解题过程中学生思路的详细建模，实现了对学生思维能力的有效刻画。在此基础上，本研究还开发实现了一个解题过程自动评估系统，能够准确指出学生在解题过程中出现错误的具体步骤，进行错因分析，并为教师提供班级学生的易错点与错因统计。在真实教育场景下的用户实验与访谈表明，这一系统不仅提高了作业批改的效率和准确性，还为学生提供了个性化的反馈，帮助他们更好地理解和改进自己的解题思路。

具体成果总结如下：

\begin{enumerate}
    \item 提出了一种基于LLM的学生思维能力评估方法，通过对解题过程中学生思路的详细建模，实现了对学生思维能力的有效评估。
    \item 自动化作业批改：通过LLM技术实现了对学生解答题作业的自动化批改，可以减轻教师的工作负担，提高了批改作业效率。
    \item 个性化错因定位与分析：系统能够通过分析学生解题过程来找出真正的错误步骤，并提供详细的错因分析，为学生提供个性化的反馈。
    \item 教师备课与教研支持：系统为教师提供了班级整体的错误统计和分析数据，帮助教师更好地了解学生的思维模式和知识掌握情况，从而制定更加个性化的教学策略。
\end{enumerate}

\section{局限性}

目前的工作是将 LLM 应用于教育领域进行思维能力建模以及自动化批改的初步尝试，还存在一些局限性。

首先，本研究的系统还有一些功能和性能上的不足。目前提出的自动批改方案只能支持具有唯一解题路径的题目，无法覆盖一题多解的情况。根据上文的实验结果，错误判断和错因分析的准确性并不是很高，虽然系统给出的结果足够有参考价值，但评判质量并不能和专业教师媲美。

其次，虽然系统已经能够达成了可观的效果，LLM的实际使用仍然面对一定的局限性。一方面，系统在分析学生解答时需要多次调用LLM的API，一份解答的分析大约会调用 15 到 20 次，这会带来相当大的时间开销：在单线程依次调用的情况下，一份解答需要数分钟才能得到分析结果，这严重影响了系统的实时性。另一方面，由于调用次数较多，成本也会相应增加，这对于大规模应用来说是一个不小的挑战。

最后，本研究的实验数据集规模较小，仅覆盖了小部分学生和数个题目类型，因此模型的泛化能力有待进一步验证。

\section{总结与展望}

本研究不仅在理论上为大语言模型在教育领域中的应用提供了新的视角和方法，在实践上也展示了其在提高教育效率、实现个性化教学和促进教育公平等方面的巨大潜力。利用LLM搭建的智能体系统可以自动化地批改大量解答题作业，极大地减轻了教师的工作负担；通过对学生解题过程的详细建模，LLM可以提供个性化的反馈，帮助学生更好地理解和改进自己的解题思路；此外，LLM还可以进行大规模的数据分析，为教师提供班级整体的错误统计和分析数据，帮助教师针对性地调整教学策略。

展望未来，随着LLM技术的不断发展和完善，其技术在教育领域的应用将更加广泛和深入。在此基础上，未来的研究可以进一步优化解题过程的建模方法，提升错因分析的准确性和智能化程度；收集足够多的数据后，可以探索如何设计无需专家手动标注标准答案就可以分析学生群体的解答的系统，从而增加系统的可扩展性、降低使用成本；同时，可以探索将该技术应用于更多类型的学科和教育场景，如中学教育中数学以外的其他学科。

本研究的成果不仅丰富了LLM的应用场景，也为教育领域的技术创新提供了新的思路和方法​​。通过本研究的探索和实践，希望能为现代教育的变革和发展贡献一份力量，推动教育向更加智能化、个性化和公平化的方向发展。